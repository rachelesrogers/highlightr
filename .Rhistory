transcript_example_rename <- dplyr::rename(transcript_example, text=Text)
toks_transcript <- token_transcript(transcript_example_rename)
transcript_token <- toks_transcript
note_token <- toks_comment
collocate_length <- 5
#Same as previous notes
descript_ngrams <- quanteda::tokens_ngrams(transcript_token, n = collocate_length, skip = 0L, concatenator = " ")
descript_ngram_df <- data.frame(unlist(descript_ngrams))
rel_freq <-as.data.frame(table(descript_ngram_df))
descript_ngram_df <- dplyr::left_join(descript_ngram_df, rel_freq)
names(descript_ngram_df) <- c("collocation", "transcript_freq")
descript_ngram_df <-data.frame(collocation = descript_ngram_df$collocation,
transcript_freq = descript_ngram_df$transcript_freq)
for (i in 1:collocate_length){
descript_ngram_df <- cbind(descript_ngram_df, seq(from=i, to = dim(descript_ngram_df)[1]+(i-1)))
names(descript_ngram_df)[ncol(descript_ngram_df)]<-paste0("word_",i)
}
descript_ngram_df$first_word <- stringr::word(descript_ngram_df$collocation,1)
col_descript <- note_token %>% quanteda.textstats::textstat_collocations(min_count = 1,
size=collocate_length)
col_merged_descript <- dplyr::left_join(descript_ngram_df, col_descript)
col_merged_descript$count <- replace(col_merged_descript$count,is.na(col_merged_descript$count),0)
# Finding collocations that do not directly match the transcript
mismatches <- dplyr::anti_join(col_descript, descript_ngram_df)
fuzzyjoin::stringdist_join(descript_ngram_df, mismatches,
by='collocation', #match based on collocation
mode='right', #use right join
method = "lv", #use levenshtein distance metric
max_dist=99,
distance_col='dist')
library(zoomerjoin)
zoomerjoin::euclidean_right_join(descript_ngram_df, mismatches,
by='collocation', #match based on collocation
threshold=99)
zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation')
names(mismatches)
zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column=dist)
zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist")
zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=60)
zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=90)
zoomerjoin::hamming_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist")
zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=200)
zoomerjoin::hamming_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=200)
# Finding collocations that do not directly match the transcript
mismatches <- dplyr::anti_join(col_descript, descript_ngram_df)
fuzzy_matches <- zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=90)%>%
dplyr::group_by(collocation.y) %>%
dplyr::slice_max(order_by=dist, n=1) #finding the closest match
View(fuzzy_matches)
fuzzy_matches <- zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=90, threshold=0.5)%>%
dplyr::group_by(collocation.y) %>%
dplyr::slice_max(order_by=dist, n=1) #finding the closest match
fuzzy_matches <- zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=200, threshold=0.5)%>%
dplyr::group_by(collocation.y) %>%
dplyr::slice_max(order_by=dist, n=1) #finding the closest match
fuzzy_matches <- zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=2000, threshold=0.5)%>%
dplyr::group_by(collocation.y) %>%
dplyr::slice_max(order_by=dist, n=1) #finding the closest match
View(fuzzy_matches)
#counting the number of closest matches per collocation
close_freq<-as.data.frame(table(fuzzy_matches$collocation.y))
close_freq
fuzzy_matches <- zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=2000, threshold=0.5)%>%
dplyr::group_by(collocation.y) %>%
dplyr::slice_max(order_by=dist, n=1) %>% #finding the closest match
filter(!is.na(collocation.x))
fuzzy_matches <- zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=2000, threshold=0.5)%>%
dplyr::group_by(collocation.y) %>%
dplyr::slice_max(order_by=dist, n=1)
fuzzy_matches <- zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=2000, threshold=0.5)%>%
dplyr::group_by(collocation.y) %>%
dplyr::slice_max(order_by=dist, n=1) %>% #finding the closest match
filter(!is.na("collocation.x"))
View(fuzzy_matches)
fuzzy_matches <- zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=2000, threshold=0.5)%>%
dplyr::group_by(collocation.y) %>%
dplyr::slice_max(order_by=dist, n=1)
View(fuzzy_matches)
View(fuzzy_matches %>% filter(!is.na(collocation.x)))
View(fuzzy_matches$collocation.x)
zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=2000, threshold=0.5)
fuzzy_matches <- zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=2000, threshold=0.5)%>%
dplyr::filter(!is.na(collocation.x)) %>%
dplyr::group_by(collocation.y) %>%
dplyr::slice_max(order_by=dist, n=1)
View(fuzzy_matches)
#counting the number of closest matches per collocation
close_freq<-as.data.frame(table(fuzzy_matches$collocation.y))
close_freq <- close_freq %>% dplyr::rename("collocation.y"="Var1", "close_freq"="Freq")
fuzzy_matches <- dplyr::left_join(fuzzy_matches, close_freq)
View(fuzzy_matches)
#Fuzzy matches weight
fuzzy_matches$weighted_count <- (fuzzy_matches$count*fizzy_matches$dist)/(fuzzy_matches$close_freq)
#Fuzzy matches weight
fuzzy_matches$weighted_count <- (fuzzy_matches$count*fuzzy_matches$dist)/(fuzzy_matches$close_freq)
#Counting up the number of fuzzy matches per transcript collocation
fuzzy_col <-fuzzy_matches %>% dplyr::group_by(collocation.x) %>%
dplyr::summarise (fuzzy_count = sum(weighted_count))
fuzzy_col
fuzzy_col <- fuzzy_col %>% dplyr::rename("collocation"="collocation.x")
col_merged_fuzzy <- dplyr::left_join(col_merged_descript, fuzzy_col)
col_merged_fuzzy$fuzzy_count <- replace(col_merged_fuzzy$fuzzy_count, is.na(col_merged_fuzzy$fuzzy_count),0)
#Counting up fuzzy and non-fuzzy matches
col_merged_fuzzy$final_count <- col_merged_fuzzy$count+col_merged_fuzzy$fuzzy_count
col_descript_long <- col_merged_fuzzy %>%  tidyr::pivot_longer(cols = 3:(collocate_length+2),
names_to = "col_number",
names_prefix = "word_",
values_to = "word_number"
)
col_descript_long$rel_freq <- col_descript_long$final_count/col_descript_long$transcript_freq
descript_tomerge <- col_descript_long %>% dplyr::select(rel_freq, col_number, word_number) %>%
tidyr::pivot_wider(names_from = col_number, values_from = rel_freq, names_prefix = "col_")
add_word<-descript_ngram_df %>% dplyr::select(word_1, first_word, collocation) %>%
dplyr::rename("word_number"="word_1")
descript_tomerge <- dplyr::left_join(descript_tomerge, add_word)
descript_tomerge<-descript_tomerge %>% dplyr::rename("to_merge"="first_word")
for (i in 2:collocate_length){
descript_tomerge[dim(descript_tomerge)[1]-(collocate_length-i),]$to_merge <-
stringr::word(descript_tomerge[dim(descript_tomerge)[1]-(collocate_length-1),]$collocation, i)
}
descript_tomerge
devtools::document()
import(zoomerjoin)
use_package(zoomerjoin)
use_package("zoomerjoin")
check()
pkgbuild::check_build_tools(debug = TRUE)
check()
pkgbuild::check_build_tools(debug = TRUE)
check()
dash_test <-
data.frame(ID=1:6,
Notes=c("dash-name did this", "year 1892-1777 was significant", "another dash-name did this",
"in year 1892-1777 dash-name did another thing", "in an example - here is a dash space",
"in an example - here is a dash space with dash-name and year 1892-1777"))
comment_example_rename <- dplyr::rename(dash_test, page_notes=Notes)
toks_comment <- token_comments(comment_example_rename)
dash_transcript <- data.frame(Text="in an example - here is a dash space
in the year 1892-1777 dash-name did this")
transcript_example_rename <- dplyr::rename(dash_transcript, text=Text)
toks_transcript <- token_transcript(transcript_example_rename)
collocation_object <- collocate_comments_fuzzy(toks_transcript, toks_comment, collocate_length = 2)
transcript_token<- toks_transcript
note_token <- toks_comment
collocate_length <- 2
collocation.y <- dist <- collocation.x <- weighted_count <- col_number <- word_number <-
word_1 <- first_word <- collocation <- NULL
`%>%` <- magrittr::`%>%`
#Same as previous notes
descript_ngrams <- quanteda::tokens_ngrams(transcript_token, n = collocate_length, skip = 0L, concatenator = " ")
descript_ngram_df <- data.frame(unlist(descript_ngrams))
rel_freq <-as.data.frame(table(descript_ngram_df))
descript_ngram_df <- dplyr::left_join(descript_ngram_df, rel_freq)
names(descript_ngram_df) <- c("collocation", "transcript_freq")
descript_ngram_df <-data.frame(collocation = descript_ngram_df$collocation,
transcript_freq = descript_ngram_df$transcript_freq)
for (i in 1:collocate_length){
descript_ngram_df <- cbind(descript_ngram_df, seq(from=i, to = dim(descript_ngram_df)[1]+(i-1)))
names(descript_ngram_df)[ncol(descript_ngram_df)]<-paste0("word_",i)
}
descript_ngram_df$first_word <- stringr::word(descript_ngram_df$collocation,1)
col_descript <- note_token %>% quanteda.textstats::textstat_collocations(min_count = 1,
size=collocate_length)
col_merged_descript <- dplyr::left_join(descript_ngram_df, col_descript)
col_merged_descript$count <- replace(col_merged_descript$count,is.na(col_merged_descript$count),0)
# Finding collocations that do not directly match the transcript
mismatches <- dplyr::anti_join(col_descript, descript_ngram_df)
mismatches
descript_ngram_df
fuzzy_matches <- zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=2000, threshold=0.5)%>%
dplyr::filter(!is.na(collocation.x)) %>%
dplyr::group_by(collocation.y) %>%
dplyr::slice_max(order_by=dist, n=1) #finding closest match based on Jaccard Distance
fuzzy_matches
dash_test
is.na(fuzzy_matches)
dim(fuzzy_matches)
fuzzy_matches <- zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=2000, threshold=0.1)%>%
dplyr::filter(!is.na(collocation.x)) %>%
dplyr::group_by(collocation.y) %>%
dplyr::slice_max(order_by=dist, n=1) #finding closest match based on Jaccard Distance
dash_test
dash_transcript
mismatches
descript_ngram_df
fuzzy_matches <- zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=2000, threshold=0.25)%>%
dplyr::filter(!is.na(collocation.x)) %>%
dplyr::group_by(collocation.y) %>%
dplyr::slice_max(order_by=dist, n=1) #finding closest match based on Jaccard Distance
fuzzy_matches <- zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=20000, threshold=0.25)%>%
dplyr::filter(!is.na(collocation.x)) %>%
dplyr::group_by(collocation.y) %>%
dplyr::slice_max(order_by=dist, n=1) #finding closest match based on Jaccard Distance
fuzzy_matches <- zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=20000, threshold=0.4)%>%
dplyr::filter(!is.na(collocation.x)) %>%
dplyr::group_by(collocation.y) %>%
dplyr::slice_max(order_by=dist, n=1) #finding closest match based on Jaccard Distance
fuzzy_matches
load_all()
collocation_object <- collocate_comments_fuzzy(toks_transcript, toks_comment, collocate_length = 2)
frequency_test <- transcript_frequency(transcript_example_rename, collocation_object)
expect_identical(frequency_test$to_merge, c("in","an","example","","here","is","a","dash","space","in",
"the","year","1892","","1777","dash","","name","did","this"))
frequency_test
check()
rep_test <-
data.frame(ID=1:6,
Notes=c(rep("in an example", 3)))
rep_test
rep_test <-
data.frame(ID=1:6,
Notes=c(rep("in an example", 6)))
comment_example_rename <- dplyr::rename(rep_test, page_notes=Notes)
toks_comment <- token_comments(comment_example_rename)
dash_transcript <- data.frame(Text="in an example - here is a dash space
in the year 1892-1777 dash-name did this")
transcript_example_rename <- dplyr::rename(dash_transcript, text=Text)
toks_transcript <- token_transcript(transcript_example_rename)
collocation_object <- collocate_comments_fuzzy(toks_transcript, toks_comment, collocate_length = 2)
dim(fuzzy_matches)
fuzzy_matches
load_all()
dash_test <-
data.frame(ID=1:6,
Notes=c("dash-name did this", "year 1892-1777 was significant", "another dash-name did this",
"in year 1892-1777 dash-name did another thing", "in an example - here is a dash space",
"in an example - here is a dash space with dash-name and year 1892-1777"))
comment_example_rename <- dplyr::rename(dash_test, page_notes=Notes)
toks_comment <- token_comments(comment_example_rename)
dash_transcript <- data.frame(Text="in an example - here is a dash space
in the year 1892-1777 dash-name did this")
transcript_example_rename <- dplyr::rename(dash_transcript, text=Text)
toks_transcript <- token_transcript(transcript_example_rename)
collocation_object <- collocate_comments_fuzzy(toks_transcript, toks_comment, collocate_length = 2)
rep_test <-
data.frame(ID=1:6,
Notes=c(rep("in an example", 6)))
comment_example_rename <- dplyr::rename(rep_test, page_notes=Notes)
toks_comment <- token_comments(comment_example_rename)
dash_transcript <- data.frame(Text="in an example - here is a dash space
in the year 1892-1777 dash-name did this")
transcript_example_rename <- dplyr::rename(dash_transcript, text=Text)
toks_transcript <- token_transcript(transcript_example_rename)
collocation_object <- collocate_comments_fuzzy(toks_transcript, toks_comment, collocate_length = 2)
collocation_object
frequency_test <- transcript_frequency(transcript_example_rename, collocation_object)
frequency_test
frequency_test$Freq[1:3]
frequency_test$Freq[1:3]==c(6,6,3)
check()
check()
devtools::build_rmd("vignettes/highlightr.Rmd")
load_all()
comment_example_rename <- dplyr::rename(comment_example, page_notes=Notes)
toks_comment <- token_comments(comment_example_rename)
transcript_example_rename <- dplyr::rename(transcript_example, text=Text)
toks_transcript <- token_transcript(transcript_example_rename)
collocation_object <- collocate_comments_fuzzy(toks_transcript, toks_comment)
collocation_object <- collocate_comments_fuzzy(toks_transcript, toks_comment)
head(collocation_object)
merged_frequency <- transcript_frequency(transcript_example_rename, collocation_object)
View(merged_frequency)
View(collocation_object)
transcript_token <- toks_transcript
note_token <- toks_comment
#Same as previous notes
descript_ngrams <- quanteda::tokens_ngrams(transcript_token, n = collocate_length, skip = 0L, concatenator = " ")
descript_ngram_df <- data.frame(unlist(descript_ngrams))
rel_freq <-as.data.frame(table(descript_ngram_df))
descript_ngram_df <- dplyr::left_join(descript_ngram_df, rel_freq)
names(descript_ngram_df) <- c("collocation", "transcript_freq")
descript_ngram_df <-data.frame(collocation = descript_ngram_df$collocation,
transcript_freq = descript_ngram_df$transcript_freq)
for (i in 1:collocate_length){
descript_ngram_df <- cbind(descript_ngram_df, seq(from=i, to = dim(descript_ngram_df)[1]+(i-1)))
names(descript_ngram_df)[ncol(descript_ngram_df)]<-paste0("word_",i)
}
descript_ngram_df$first_word <- stringr::word(descript_ngram_df$collocation,1)
col_descript <- note_token %>% quanteda.textstats::textstat_collocations(min_count = 1,
size=collocate_length)
col_merged_descript <- dplyr::left_join(descript_ngram_df, col_descript)
col_merged_descript$count <- replace(col_merged_descript$count,is.na(col_merged_descript$count),0)
# Finding collocations that do not directly match the transcript
mismatches <- dplyr::anti_join(col_descript, descript_ngram_df)
View(mismatches)
View(fuzzy_matches)
View(descript_ngram_df)
fuzzy_matches <- zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=20000, threshold=0.4)%>%
dplyr::filter(!is.na(collocation.x)) %>%
dplyr::group_by(collocation.y) %>%
dplyr::slice_max(order_by=dist, n=1) #finding closest match based on Jaccard Distance
View(fuzzy_matches)
close_freq<-as.data.frame(table(fuzzy_matches$collocation.y))
close_freq <- close_freq %>% dplyr::rename("collocation.y"="Var1", "close_freq"="Freq")
View(close_freq)
fuzzy_matches <- dplyr::left_join(fuzzy_matches, close_freq)
View(fuzzy_matches)
# Finding collocations that do not directly match the transcript
mismatches <- dplyr::anti_join(col_descript, descript_ngram_df)
View(mismatches)
View(col_descript)
View(note_token)
check()
load_all()
toks_comment <- token_comments(highlightr::wiki_pages)
transcript_example_rename <- data.frame(text=wiki_pages[1,])
toks_transcript <- token_transcript(transcript_example_rename)
collocation_object <- collocate_comments_fuzzy(toks_transcript, toks_comment)
collocation_object <- collocate_comments_fuzzy(toks_transcript, toks_comment)
head(collocation_object)
collocation_object <- collocate_comments_fuzzy(toks_transcript, toks_comment)
collocation_object2 <- collocate_comments(toks_transcript, toks_comment)
head(collocation_object2)
transcript_example_rename2 <- data.frame(text=wiki_pages[dim(wiki_pages)[1],])
toks_transcript2 <- token_transcript(transcript_example_rename2)
collocation_object2 <- collocate_comments_fuzzy(toks_transcript2, toks_comment)
collocation_object2 <- collocate_comments_fuzzy(toks_transcript2, toks_comment)
merged_frequency2 <- transcript_frequency(transcript_example_rename2, collocation_object2)
merged_frequency2
min(merged_frequency2$Freq)
View(merged_frequency2)
freq_plot2 <- collocation_plot(merged_frequency2)
page_highlight2 <- highlighted_text(freq_plot2, labels=c("(fewest articles)", "(most articles)"))
View(page_highlight2)
page_highlight2
freq_plot2$freq
View(freq_plot2$freq)
comment_example_rename <- dplyr::rename(comment_example, page_notes=Notes)
toks_comment <- token_comments(comment_example_rename)
transcript_example_rename <- dplyr::rename(transcript_example, text=Text)
toks_transcript <- token_transcript(transcript_example_rename)
collocation_object <- collocate_comments_fuzzy(toks_transcript, toks_comment)
View(collocation_object)
merged_frequency <- transcript_frequency(transcript_example_rename, collocation_object)
View(merged_frequency)
check()
use_release_issue()
urlchecker::url_check()
devtools::build_readme()
devtools::check(remote = TRUE, manual = TRUE)
---
output: github_document
library(tinytex)
tl_pkgs()
tinytex::parse_install()
tinytex::parse_install(text = "`makeindex` not found")
tinytex::parse_install(text = "! LaTeX Error: File `makeidx' not found.")
devtools::check(remote = TRUE, manual = TRUE)
devtools::build_manual()
tinytex::tlmgr_install("makeindex")
devtools::build_manual()
devtools::check(remote = TRUE, manual = TRUE)
comment_example_rename <- dplyr::rename(comment_example, page_notes=Notes)
toks_comment <- token_comments(comment_example_rename)
transcript_example_rename <- dplyr::rename(transcript_example, text=Text)
toks_transcript <- token_transcript(transcript_example_rename)
load_all()
collocation_object <- collocate_comments_fuzzy(toks_transcript, toks_comment)
transcript_token<- toks_transcript
note_token <- toks_comment
collocate_length = 5
#Same as previous notes
descript_ngrams <- quanteda::tokens_ngrams(transcript_token, n = collocate_length, skip = 0L, concatenator = " ")
descript_ngram_df <- data.frame(unlist(descript_ngrams))
rel_freq <-as.data.frame(table(descript_ngram_df))
descript_ngram_df <- dplyr::left_join(descript_ngram_df, rel_freq)
names(descript_ngram_df) <- c("collocation", "transcript_freq")
descript_ngram_df <-data.frame(collocation = descript_ngram_df$collocation,
transcript_freq = descript_ngram_df$transcript_freq)
for (i in 1:collocate_length){
descript_ngram_df <- cbind(descript_ngram_df, seq(from=i, to = dim(descript_ngram_df)[1]+(i-1)))
names(descript_ngram_df)[ncol(descript_ngram_df)]<-paste0("word_",i)
}
descript_ngram_df$first_word <- stringr::word(descript_ngram_df$collocation,1)
col_descript <- note_token %>% quanteda.textstats::textstat_collocations(min_count = 1,
size=collocate_length)
col_merged_descript <- dplyr::left_join(descript_ngram_df, col_descript)
col_merged_descript$count <- replace(col_merged_descript$count,is.na(col_merged_descript$count),0)
# Finding collocations that do not directly match the transcript
mismatches <- dplyr::anti_join(col_descript, descript_ngram_df)
fuzzy_matches <- zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=10000, threshold=0.4)%>%
dplyr::filter(!is.na(collocation.x)) %>%
dplyr::group_by(collocation.y) %>%
dplyr::slice_max(order_by=dist, n=1) #finding closest match based on Jaccard Distance
check()
fuzzy_matches <- zoomerjoin::jaccard_right_join(descript_ngram_df, mismatches,
by='collocation', similarity_column="dist", n_bands=5000, threshold=0.4)%>%
dplyr::filter(!is.na(collocation.x)) %>%
dplyr::group_by(collocation.y) %>%
dplyr::slice_max(order_by=dist, n=1) #finding closest match based on Jaccard Distance
check()
document()
devtools::build_readme()
devtools::check(remote = TRUE, manual = TRUE)
devtools::check_win_devel()
View(comment_example_rename)
View(comment_example_rename[1:50])
View(comment_example_rename[1:50,])
check()
document()
revdepcheck::revdep_check(num_workers = 4)
install.packages("revdepcheck")
revdepcheck::revdep_check(num_workers = 4)
devtools::install_github("r-lib/revdepcheck")
revdepcheck::revdep_check(num_workers = 4)
detach(highlightr)
detach("highlightr")
revdepcheck::revdep_check(num_workers = 4)
devtools::build_readme()
devtools::check(remote = TRUE, manual = TRUE)
devtools::check_win_devel()
urlchecker::url_check()
library(devtools)
install.packages("devtools")
install.packages("urlchecker")
urlchecker::url_check()
devtools::build_readme()
devtools::check(remote = TRUE, manual = TRUE)
devtools::check(remote = TRUE, manual = TRUE)
devtools::check(remote = TRUE, manual = TRUE)
install.packages("rhub")
devtools::check(remote = TRUE, manual = TRUE)
devtools::check(remote = TRUE, manual = TRUE)
devtools::check_win_devel()
devtools::check(remote = TRUE, manual = TRUE)
usethis::use_version('minor')
devtools::check(remote = TRUE, manual = TRUE)
devtools::check(remote = TRUE, manual = TRUE)
devtools::check(remote = TRUE, manual = TRUE)
devtools::submit_cran()
check()
library(devtools)
check()
check()
use_release_issue()
rhub::check(platforms = "debian-gcc-release")
check(platforms = "debian-gcc-release")
check_rhub(platforms = "debian-gcc-release")
?rhubv2
rhub_check(platforms = "debian-gcc-release")
library(rhub)
rhub_check(platforms = "debian-gcc-release")
rhub::rhub_platforms()
rhub_check(l)
rhub_check()
rhub_check(platforms = "ubuntu-gcc12")
check_on_debian()
rhub::rhub_setup()
check_on_debian()
rhub_check(platforms = "ubuntu-gcc12")
rhub_platforms()
check_on_linux()
rhub_check()
rhub_check(gh_url = "https://github.com/rachelesrogers/highlightr")
.Last.error
rhub::check(platforms = "debian-gcc-release")
check()
devtools::check()
devtools::check()
urlchecker::url_check()
devtools::build_readme()
devtools::check(remote = TRUE, manual = TRUE)
devtools::check_win_devel()
devtools::check_rhub()
rhub::check(platforms = "debian-gcc-release")
rhub_check()
devtools::build()
rhub_check("C:/Users/rache/Documents/Work/highlightr_1.1.0.tar.gz")
rhub::check("C:/Users/rache/Documents/Work/highlightr_1.1.0.tar.gz")
rhub::rhub_check()
rhub_setup()
rhub::rhub_doctor()
rhub::rhub_doctor()
rhub::rhub_check()
rhub::rhub_check()
devtools::build_readme()
devtools::check(remote = TRUE, manual = TRUE)
devtools::check(remote = TRUE, manual = TRUE)
devtools::check(remote = TRUE, manual = TRUE)
devtools::check_win_devel()
usethis::use_version('patch')
devtools::submit_cran()
Sys.setenv("OMP_THREAD_LIMIT" = 2)
use_release_issue()
urlchecker::url_check()
devtools::build_readme()
devtools::check(remote = TRUE, manual = TRUE)
